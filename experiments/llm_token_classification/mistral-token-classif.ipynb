{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T13:00:12.237885Z",
     "iopub.status.busy": "2025-09-04T13:00:12.237581Z",
     "iopub.status.idle": "2025-09-04T13:00:17.800865Z",
     "shell.execute_reply": "2025-09-04T13:00:17.799959Z",
     "shell.execute_reply.started": "2025-09-04T13:00:12.237856Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install mistral-common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T13:01:06.870688Z",
     "iopub.status.busy": "2025-09-04T13:01:06.869942Z",
     "iopub.status.idle": "2025-09-04T13:01:16.130608Z",
     "shell.execute_reply": "2025-09-04T13:01:16.129931Z",
     "shell.execute_reply.started": "2025-09-04T13:01:06.870658Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import logging\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Any, Optional, Tuple\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import LinearLR\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModel, \n",
    "    AutoConfig,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from huggingface_hub import login\n",
    "\n",
    "\n",
    "HF_TOKEN = \"\"\n",
    "login(token=HF_TOKEN)\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"🚀 Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T13:01:16.139939Z",
     "iopub.status.busy": "2025-09-04T13:01:16.139535Z",
     "iopub.status.idle": "2025-09-04T13:01:16.164096Z",
     "shell.execute_reply": "2025-09-04T13:01:16.163475Z",
     "shell.execute_reply.started": "2025-09-04T13:01:16.139898Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainingConfig:\n",
    "    \"\"\"Training configuration optimized for Kaggle.\"\"\"\n",
    "    model_name: str = \"mistralai/Ministral-8B-Instruct-2410\"\n",
    "    max_length: int = 96\n",
    "    batch_size: int = 12\n",
    "    learning_rate: float = 1e-4\n",
    "    num_epochs: int = 1\n",
    "    warmup_steps: int = 150\n",
    "    weight_decay: float = 0.01\n",
    "    gradient_accumulation_steps: int = 3\n",
    "    max_grad_norm: float = 0.5\n",
    "    save_steps: int = 500\n",
    "    eval_steps: int = 250\n",
    "    logging_steps: int = 50\n",
    "    output_dir: str = \"./ministral_token_classifier\"\n",
    "    seed: int = 42\n",
    "\n",
    "\n",
    "config = TrainingConfig()\n",
    "print(f\"📋 Configuration:\")\n",
    "print(f\"   Model: {config.model_name}\")\n",
    "print(f\"   Batch size: {config.batch_size}\")\n",
    "print(f\"   Learning rate: {config.learning_rate}\")\n",
    "print(f\"   Max length: {config.max_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simplefied Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T13:01:16.165519Z",
     "iopub.status.busy": "2025-09-04T13:01:16.165227Z",
     "iopub.status.idle": "2025-09-04T13:01:16.185599Z",
     "shell.execute_reply": "2025-09-04T13:01:16.184964Z",
     "shell.execute_reply.started": "2025-09-04T13:01:16.165492Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class FastPIITokenDataset(Dataset):\n",
    "    \"\"\"Ultra-fast PyTorch Dataset - NO tokenization during training!\"\"\"\n",
    "    \n",
    "    def __init__(self, dataset: Dict[str, Any], max_length: int = 96):\n",
    "        self.texts = dataset['texts']\n",
    "        self.token_ids = dataset['token_ids']\n",
    "        self.label_ids = dataset['label_ids']\n",
    "        self.label_to_id = dataset['label_to_id']\n",
    "        self.id_to_label = dataset['id_to_label']\n",
    "        self.max_length = max_length\n",
    "        print(f\"FastPIITokenDataset: {len(self.texts)} examples\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        token_ids = self.token_ids[idx]\n",
    "        label_ids = self.label_ids[idx]\n",
    "        \n",
    "        # Pad/truncate\n",
    "        input_ids = self._pad_or_truncate(token_ids, self.max_length, 0)\n",
    "        labels = self._pad_or_truncate(label_ids, self.max_length, -100)\n",
    "        attention_mask = [1 if tid != 0 else 0 for tid in input_ids]\n",
    "        \n",
    "        return {\n",
    "            'input_ids': torch.tensor(input_ids, dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(attention_mask, dtype=torch.long),\n",
    "            'labels': torch.tensor(labels, dtype=torch.long)\n",
    "        }\n",
    "    \n",
    "    def _pad_or_truncate(self, seq, max_len, pad_val):\n",
    "        return seq[:max_len] + [pad_val] * max(0, max_len - len(seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T13:01:17.979226Z",
     "iopub.status.busy": "2025-09-04T13:01:17.978950Z",
     "iopub.status.idle": "2025-09-04T13:01:17.988564Z",
     "shell.execute_reply": "2025-09-04T13:01:17.987766Z",
     "shell.execute_reply.started": "2025-09-04T13:01:17.979204Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class MinistralTokenClassifier(nn.Module):\n",
    "    \"\"\"Ministral-8B model with token classification head - Optimized version.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str, num_labels: int, freeze_backbone: bool = True):\n",
    "        \"\"\"\n",
    "        Initialize the model.\n",
    "        \n",
    "        Args:\n",
    "            model_name: Pre-trained model name\n",
    "            num_labels: Number of classification labels\n",
    "            freeze_backbone: Whether to freeze the backbone model\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        print(f\"Loading model: {model_name}\")\n",
    "        \n",
    "        self.config = AutoConfig.from_pretrained(model_name)\n",
    "        self.backbone = AutoModel.from_pretrained(\n",
    "            model_name,\n",
    "            torch_dtype=torch.bfloat16,\n",
    "            device_map=\"auto\",\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "        \n",
    "        if freeze_backbone:\n",
    "            for param in self.backbone.parameters():\n",
    "                param.requires_grad = False\n",
    "            print(\"Backbone model frozen\")\n",
    "        \n",
    "        hidden_size = self.config.hidden_size\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.classifier = nn.Linear(hidden_size, num_labels)\n",
    "        \n",
    "        self.classifier = self.classifier.to(dtype=torch.bfloat16)\n",
    "        \n",
    "        nn.init.normal_(self.classifier.weight, std=0.02)\n",
    "        nn.init.zeros_(self.classifier.bias)\n",
    "        \n",
    "        self.num_labels = num_labels\n",
    "        \n",
    "        print(f\"Model initialized with {num_labels} labels\")\n",
    "        print(f\"Backbone dtype: {next(self.backbone.parameters()).dtype}\")\n",
    "        print(f\"Classifier dtype: {self.classifier.weight.dtype}\")\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask=None, labels=None):\n",
    "        \"\"\"Forward pass.\"\"\"\n",
    "        outputs = self.backbone(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            output_hidden_states=True,\n",
    "            use_cache=False\n",
    "        )\n",
    "        \n",
    "        hidden_states = outputs.last_hidden_state  # [batch_size, seq_len, hidden_size]\n",
    "        \n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "        \n",
    "        hidden_states = hidden_states.to(self.classifier.weight.dtype)\n",
    "        \n",
    "        logits = self.classifier(hidden_states)  # [batch_size, seq_len, num_labels]\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "        \n",
    "        return {\n",
    "            'loss': loss,\n",
    "            'logits': logits\n",
    "        }\n",
    "\n",
    "print(\"Optimized model class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T13:01:22.231046Z",
     "iopub.status.busy": "2025-09-04T13:01:22.230770Z",
     "iopub.status.idle": "2025-09-04T13:01:23.548802Z",
     "shell.execute_reply": "2025-09-04T13:01:23.548025Z",
     "shell.execute_reply.started": "2025-09-04T13:01:22.231025Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "train_dataset_path = \"/kaggle/input/mistral-token-classif-english/train_dataset.pkl\"\n",
    "val_dataset_path = \"/kaggle/input/mistral-token-classif-english/val_dataset.pkl\"\n",
    "\n",
    "print(\"Loading datasets...\")\n",
    "\n",
    "with open(train_dataset_path, 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "\n",
    "train_dataset = FastPIITokenDataset(train_data, config.max_length)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=config.batch_size, \n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "val_dataloader = None\n",
    "if os.path.exists(val_dataset_path):\n",
    "    with open(val_dataset_path, 'rb') as f:\n",
    "        val_data = pickle.load(f)\n",
    "    \n",
    "    val_dataset = FastPIITokenDataset(val_data, config.max_length)\n",
    "    val_dataloader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=config.batch_size, \n",
    "        shuffle=False,\n",
    "        num_workers=2\n",
    "    )\n",
    "    print(f\"Loaded {len(val_dataset)} validation examples\")\n",
    "\n",
    "label_to_id = train_data['label_to_id']\n",
    "id_to_label = train_data['id_to_label']\n",
    "num_labels = train_data['num_labels']\n",
    "\n",
    "print(f\"Loaded {len(train_dataset)} training examples\")\n",
    "print(f\"Number of labels: {num_labels}\")\n",
    "print(f\"Labels: {list(label_to_id.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduce dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T13:04:40.900991Z",
     "iopub.status.busy": "2025-09-04T13:04:40.900476Z",
     "iopub.status.idle": "2025-09-04T13:04:41.402164Z",
     "shell.execute_reply": "2025-09-04T13:04:41.401586Z",
     "shell.execute_reply.started": "2025-09-04T13:04:40.900973Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "def reduce_dataset_size(train_data, reduction_strategy=\"random\", target_size=10000, \n",
    "                       min_examples_per_label=50, seed=42):\n",
    "    \"\"\"\n",
    "    Reduce training dataset size with different strategies.\n",
    "    \n",
    "    Args:\n",
    "        train_data: Dictionary with 'texts', 'token_ids', 'label_ids', etc.\n",
    "        reduction_strategy: 'random', 'balanced', 'stratified'\n",
    "        target_size: Target number of examples\n",
    "        min_examples_per_label: Minimum examples per label (for balanced)\n",
    "        seed: Random seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "        Reduced train_data dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    random.seed(seed)\n",
    "    \n",
    "    original_size = len(train_data['texts'])\n",
    "    print(f\"Original dataset size: {original_size:,} examples\")\n",
    "    \n",
    "    if target_size >= original_size:\n",
    "        print(\"Target size >= original size, no reduction needed\")\n",
    "        return train_data\n",
    "    \n",
    "    all_indices = list(range(original_size))\n",
    "    \n",
    "    if reduction_strategy == \"random\":\n",
    "        selected_indices = random.sample(all_indices, target_size)\n",
    "        print(f\"Random sampling: {target_size:,} examples\")\n",
    "        \n",
    "    elif reduction_strategy == \"balanced\":\n",
    "        print(f\"Balanced sampling with min {min_examples_per_label} per label...\")\n",
    "        \n",
    "        label_counts = Counter()\n",
    "        label_to_indices = {}\n",
    "        \n",
    "        for idx in all_indices:\n",
    "            example_labels = [label for label in train_data['label_ids'][idx] \n",
    "                            if label != train_data['label_to_id'].get('O', -1) and label != -100]\n",
    "            \n",
    "            for label in set(example_labels):\n",
    "                if label not in label_to_indices:\n",
    "                    label_to_indices[label] = []\n",
    "                label_to_indices[label].append(idx)\n",
    "                label_counts[label] += 1\n",
    "        \n",
    "        print(f\"Found {len(label_to_indices)} unique labels\")\n",
    "        \n",
    "        selected_indices = set()\n",
    "        \n",
    "        for label, indices in label_to_indices.items():\n",
    "            if len(indices) >= min_examples_per_label:\n",
    "                selected_indices.update(random.sample(indices, min_examples_per_label))\n",
    "            else:\n",
    "                selected_indices.update(indices)\n",
    "        \n",
    "        remaining_slots = target_size - len(selected_indices)\n",
    "        if remaining_slots > 0:\n",
    "            remaining_indices = [idx for idx in all_indices if idx not in selected_indices]\n",
    "            if remaining_indices:\n",
    "                additional_indices = random.sample(\n",
    "                    remaining_indices, \n",
    "                    min(remaining_slots, len(remaining_indices))\n",
    "                )\n",
    "                selected_indices.update(additional_indices)\n",
    "        \n",
    "        selected_indices = list(selected_indices)[:target_size]\n",
    "        \n",
    "    elif reduction_strategy == \"stratified\":\n",
    "        print(f\"📊 Stratified sampling by text length and label diversity...\")\n",
    "        \n",
    "        features = []\n",
    "        for idx in all_indices:\n",
    "            text_length = len(train_data['texts'][idx])\n",
    "            unique_labels = len(set([label for label in train_data['label_ids'][idx] \n",
    "                                   if label != train_data['label_to_id'].get('O', -1) and label != -100]))\n",
    "            features.append((idx, text_length, unique_labels))\n",
    "        \n",
    "        features.sort(key=lambda x: (x[1], x[2]))\n",
    "        step = len(features) // target_size\n",
    "        selected_indices = [features[i][0] for i in range(0, len(features), max(1, step))][:target_size]\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown reduction strategy: {reduction_strategy}\")\n",
    "    \n",
    "    reduced_data = {}\n",
    "    for key in train_data.keys():\n",
    "        if key in ['texts', 'token_ids', 'label_ids']:\n",
    "            reduced_data[key] = [train_data[key][idx] for idx in selected_indices]\n",
    "        else:\n",
    "            reduced_data[key] = train_data[key]\n",
    "    \n",
    "    print(f\"Reduced dataset size: {len(reduced_data['texts']):,} examples\")\n",
    "    print(f\"Reduction ratio: {len(reduced_data['texts'])/original_size:.1%}\")\n",
    "    \n",
    "    if 'label_to_id' in train_data:\n",
    "        reduced_label_counts = Counter()\n",
    "        for label_seq in reduced_data['label_ids']:\n",
    "            for label in label_seq:\n",
    "                if label != train_data['label_to_id'].get('O', -1) and label != -100:\n",
    "                    reduced_label_counts[label] += 1\n",
    "        \n",
    "        print(f\"Reduced dataset has {len(reduced_label_counts)} active labels\")\n",
    "        \n",
    "        if reduced_label_counts:\n",
    "            id_to_label = train_data['id_to_label']\n",
    "            print(\"🔝 Top 10 labels in reduced dataset:\")\n",
    "            for label_id, count in reduced_label_counts.most_common(10):\n",
    "                label_name = id_to_label.get(label_id, f\"ID_{label_id}\")\n",
    "                print(f\"   {label_name}: {count:,} tokens\")\n",
    "    \n",
    "    return reduced_data\n",
    "\n",
    "REDUCTION_CONFIG = {\n",
    "    'strategy': 'balanced',\n",
    "    'target_size': 30000,\n",
    "    'min_examples_per_label': 100,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "print(\"Reducing training dataset size...\")\n",
    "print(f\"Strategy: {REDUCTION_CONFIG['strategy']}\")\n",
    "print(f\"Target size: {REDUCTION_CONFIG['target_size']:,}\")\n",
    "\n",
    "train_data = reduce_dataset_size(\n",
    "    train_data, \n",
    "    reduction_strategy=REDUCTION_CONFIG['strategy'],\n",
    "    target_size=REDUCTION_CONFIG['target_size'],\n",
    "    min_examples_per_label=REDUCTION_CONFIG['min_examples_per_label'],\n",
    "    seed=REDUCTION_CONFIG['seed']\n",
    ")\n",
    "\n",
    "print(\"Recreating dataset and dataloader...\")\n",
    "\n",
    "train_dataset = FastPIITokenDataset(train_data, config.max_length)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=config.batch_size, \n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "print(f\"New training dataset: {len(train_dataset):,} examples\")\n",
    "print(f\"New dataloader: {len(train_dataloader):,} batches\")\n",
    "\n",
    "total_steps = len(train_dataloader) * config.num_epochs // config.gradient_accumulation_steps\n",
    "print(f\"Updated total training steps: {total_steps:,}\")\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=config.warmup_steps,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "print(\"Ready to train with reduced dataset!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize model and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T13:01:28.698623Z",
     "iopub.status.busy": "2025-09-04T13:01:28.698341Z",
     "iopub.status.idle": "2025-09-04T13:04:40.899018Z",
     "shell.execute_reply": "2025-09-04T13:04:40.898192Z",
     "shell.execute_reply.started": "2025-09-04T13:01:28.698604Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "torch.manual_seed(config.seed)\n",
    "np.random.seed(config.seed)\n",
    "\n",
    "model = MinistralTokenClassifier(\n",
    "    model_name=config.model_name,\n",
    "    num_labels=57,\n",
    "    freeze_backbone=True\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable ratio: {trainable_params/total_params:.2%}\")\n",
    "\n",
    "optimizer_params = [p for p in model.parameters() if p.requires_grad]\n",
    "\n",
    "optimizer = AdamW(\n",
    "    optimizer_params,\n",
    "    lr=config.learning_rate,\n",
    "    weight_decay=config.weight_decay\n",
    ")\n",
    "\n",
    "total_steps = len(train_dataloader) * config.num_epochs // config.gradient_accumulation_steps\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=config.warmup_steps,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "print(f\"Total training steps: {total_steps}\")\n",
    "print(f\"Ready to train!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T13:04:41.403111Z",
     "iopub.status.busy": "2025-09-04T13:04:41.402907Z",
     "iopub.status.idle": "2025-09-04T13:04:41.417990Z",
     "shell.execute_reply": "2025-09-04T13:04:41.417315Z",
     "shell.execute_reply.started": "2025-09-04T13:04:41.403096Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, train_dataloader, optimizer, scheduler, epoch, config, device):\n",
    "    \"\"\"Train for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch+1}\")\n",
    "    \n",
    "    for step, batch in enumerate(progress_bar):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        \n",
    "        outputs = model(**batch)\n",
    "        loss = outputs['loss']\n",
    "        \n",
    "        loss = loss / config.gradient_accumulation_steps\n",
    "        loss.backward()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "        \n",
    "        if (step + 1) % config.gradient_accumulation_steps == 0:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        avg_loss = total_loss / num_batches\n",
    "        progress_bar.set_postfix({'loss': f'{avg_loss:.4f}'})\n",
    "        \n",
    "        if step % config.logging_steps == 0:\n",
    "            print(f\"Epoch {epoch+1}, Step {step}, Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    return total_loss / num_batches\n",
    "\n",
    "def evaluate(model, val_dataloader, id_to_label, device):\n",
    "    \"\"\"Evaluate on validation set.\"\"\"\n",
    "    if not val_dataloader:\n",
    "        print(\"No validation dataset available\")\n",
    "        return {}\n",
    "    \n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_dataloader, desc=\"Evaluating\"):\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            \n",
    "            outputs = model(**batch)\n",
    "            loss = outputs['loss']\n",
    "            logits = outputs['logits']\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            predictions = torch.argmax(logits, dim=-1)\n",
    "            \n",
    "            batch_labels = batch['labels'].cpu().numpy().flatten()\n",
    "            batch_predictions = predictions.cpu().numpy().flatten()\n",
    "            \n",
    "            mask = batch_labels != -100\n",
    "            all_labels.extend(batch_labels[mask])\n",
    "            all_predictions.extend(batch_predictions[mask])\n",
    "    \n",
    "    avg_loss = total_loss / len(val_dataloader)\n",
    "    f1 = f1_score(all_labels, all_predictions, average='weighted')\n",
    "    \n",
    "    target_names = [id_to_label[i] for i in range(len(id_to_label))]\n",
    "    report = classification_report(\n",
    "        all_labels, \n",
    "        all_predictions, \n",
    "        target_names=target_names,\n",
    "        output_dict=True,\n",
    "        zero_division=0\n",
    "    )\n",
    "    \n",
    "    print(f\"Validation Loss: {avg_loss:.4f}\")\n",
    "    print(f\"Validation F1-Score: {f1:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'loss': avg_loss,\n",
    "        'f1_score': f1,\n",
    "        'classification_report': report\n",
    "    }\n",
    "\n",
    "def save_model(model, config, label_to_id, id_to_label, output_dir):\n",
    "    \"\"\"Save the trained model.\"\"\"\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    model_state = {\n",
    "        'classifier_state_dict': model.classifier.state_dict(),\n",
    "        'config': config.__dict__,\n",
    "        'label_to_id': label_to_id,\n",
    "        'id_to_label': id_to_label,\n",
    "        'num_labels': len(label_to_id),\n",
    "        'model_name': config.model_name\n",
    "    }\n",
    "    \n",
    "    torch.save(model_state, output_path / \"pytorch_model.bin\")\n",
    "    \n",
    "    with open(output_path / \"training_config.json\", 'w') as f:\n",
    "        json.dump(config.__dict__, f, indent=2)\n",
    "    \n",
    "    print(f\"💾 Model saved to {output_path}\")\n",
    "\n",
    "print(\"✅ Training functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T13:04:41.419747Z",
     "iopub.status.busy": "2025-09-04T13:04:41.419385Z",
     "iopub.status.idle": "2025-09-04T15:20:46.768796Z",
     "shell.execute_reply": "2025-09-04T15:20:46.767792Z",
     "shell.execute_reply.started": "2025-09-04T13:04:41.419731Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Starting training...\")\n",
    "\n",
    "best_f1 = 0\n",
    "output_dir = config.output_dir\n",
    "\n",
    "for epoch in range(config.num_epochs):\n",
    "    print(f\"\\nStarting epoch {epoch + 1}/{config.num_epochs}\")\n",
    "    \n",
    "    train_loss = train_epoch(model, train_dataloader, optimizer, scheduler, epoch, config, device)\n",
    "    print(f\"Epoch {epoch + 1} - Training Loss: {train_loss:.4f}\")\n",
    "    \n",
    "    eval_results = evaluate(model, val_dataloader, id_to_label, device)\n",
    "    \n",
    "    if eval_results and eval_results['f1_score'] > best_f1:\n",
    "        best_f1 = eval_results['f1_score']\n",
    "        save_model(model, config, label_to_id, id_to_label, output_dir)\n",
    "        print(f\"New best F1-Score: {best_f1:.4f} - Model saved\")\n",
    "\n",
    "print(f\"\\nTraining completed!\")\n",
    "print(f\"Best F1-Score: {best_f1:.4f}\")\n",
    "print(f\"Model saved to: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation and cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Final evaluation on validation set\n",
    "if val_dataloader:\n",
    "    print(\"\\nFinal evaluation:\")\n",
    "    final_results = evaluate(model, val_dataloader, id_to_label, device)\n",
    "    \n",
    "    if final_results:\n",
    "        print(\"\\nClassification Report:\")\n",
    "        report = final_results['classification_report']\n",
    "        for label, metrics in report.items():\n",
    "            if isinstance(metrics, dict) and 'precision' in metrics:\n",
    "                print(f\"{label:15} - P: {metrics['precision']:.3f}, R: {metrics['recall']:.3f}, F1: {metrics['f1-score']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-01T17:59:52.958583Z",
     "iopub.status.busy": "2025-09-01T17:59:52.957843Z",
     "iopub.status.idle": "2025-09-01T17:59:52.962794Z",
     "shell.execute_reply": "2025-09-01T17:59:52.962064Z",
     "shell.execute_reply.started": "2025-09-01T17:59:52.958560Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "print(\"\\n🧹 Memory cleaned up\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8202346,
     "sourceId": 12960351,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
